{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsianghsu/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/hsianghsu/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from pprint import pprint \n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import model_selection\n",
    "from random import seed\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "from collections import OrderedDict\n",
    "from itertools import product\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import print_function # For Python 2 / 3 compatability\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADNI2 shape:  (6937, 94)\n",
      "ADNI2_impute shape:  (789, 58)\n",
      "ADNI2_remove shape:  (789, 13)\n"
     ]
    }
   ],
   "source": [
    "ADNI_merge = pd.read_csv('ADNIMERGE.csv')\n",
    "ADNI2 = ADNI_merge[ADNI_merge['COLPROT']=='ADNI2']\n",
    "print(\"ADNI2 shape: \", ADNI2.shape)\n",
    "\n",
    "ADNI2_impute = pd.read_csv('ADNI2_mb_impute_v3.csv')\n",
    "print(\"ADNI2_impute shape: \", ADNI2_impute.shape)\n",
    "\n",
    "ADNI2_remove = pd.read_csv('ADNI2_remove_all_missing_v3.csv')\n",
    "print(\"ADNI2_remove shape: \", ADNI2_remove.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'CDRSB_bl', 'ADAS11_bl', 'ADAS13_bl', 'MMSE_bl',\n",
       "       'RAVLT_immediate_bl', 'RAVLT_learning_bl', 'RAVLT_forgetting_bl',\n",
       "       'RAVLT_perc_forgetting_bl', 'FAQ_bl', 'Ventricles_bl', 'Hippocampus_bl',\n",
       "       'WholeBrain_bl', 'Entorhinal_bl', 'Fusiform_bl', 'MidTemp_bl', 'ICV_bl',\n",
       "       'MOCA_bl', 'EcogPtMem_bl', 'EcogPtLang_bl', 'EcogPtVisspat_bl',\n",
       "       'EcogPtPlan_bl', 'EcogPtOrgan_bl', 'EcogPtDivatt_bl', 'EcogPtTotal_bl',\n",
       "       'EcogSPMem_bl', 'EcogSPLang_bl', 'EcogSPVisspat_bl', 'EcogSPPlan_bl',\n",
       "       'EcogSPOrgan_bl', 'EcogSPDivatt_bl', 'EcogSPTotal_bl', 'FDG_bl',\n",
       "       'AV45_bl', 'Years_bl', 'PTEDUCAT', 'PTGENDER_Female', 'PTGENDER_Male',\n",
       "       'PTETHCAT_Hisp/Latino', 'PTETHCAT_Not Hisp/Latino',\n",
       "       'PTRACCAT_Am Indian/Alaskan', 'PTRACCAT_Asian', 'PTRACCAT_Black',\n",
       "       'PTRACCAT_Hawaiian/Other PI', 'PTRACCAT_More than one',\n",
       "       'PTRACCAT_White', 'PTMARRY_Divorced', 'PTMARRY_Married',\n",
       "       'PTMARRY_Never married', 'PTMARRY_Widowed', 'APOE4_0.0', 'APOE4_1.0',\n",
       "       'APOE4_2.0', 'FLDSTRENG_1.5 Tesla MRI', 'FLDSTRENG_3 Tesla MRI',\n",
       "       'FSVERSION_Cross-Sectional FreeSurfer (5.1)',\n",
       "       'FSVERSION_Cross-Sectional FreeSurfer (FreeSurfer Version 4.3)',\n",
       "       'DX_bl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADNI2_impute.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RID', 'PTID', 'SITE', 'COLPROT', 'ORIGPROT', 'DX_bl', 'AGE',\n",
       "       'EXAMDATE_bl', 'CDRSB_bl', 'MMSE_bl', 'PTEDUCAT', 'Female', 'Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADNI2_remove.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Narrow down to baseline-only data, and prepare X_train, y_train, X_test, and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789, 57)\n",
      "(789, 7)\n"
     ]
    }
   ],
   "source": [
    "DROP_COL_IMPUTE = [\"Years_bl\"]\n",
    "\n",
    "DROP_COL_REMOVE = ['RID', 'PTID', 'SITE', 'COLPROT', 'ORIGPROT',\n",
    "                   'EXAMDATE_bl']\n",
    "\n",
    "df_impute = ADNI2_impute.drop(DROP_COL_IMPUTE, axis=1)\n",
    "df_remove = ADNI2_remove.drop(DROP_COL_REMOVE, axis=1)\n",
    "#df_impute['PTEDUCAT'] = ADNI2[\"PTEDUCAT\"].values\n",
    "#df_remove['PTEDUCAT'] = ADNI2[\"PTEDUCAT\"].values\n",
    "print(df_impute.shape)\n",
    "print(df_remove.shape)\n",
    "#print(df_impute.columns)\n",
    "#print(df_remove.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For REMOVE:\n",
      "(588, 6)\n",
      "(588,)\n",
      "(201, 6)\n",
      "(201,)\n",
      "\n",
      "For IMPUTE:\n",
      "(588, 57)\n",
      "(588,)\n",
      "(201, 57)\n",
      "(201,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9001)\n",
    "train_percentage = 0.75\n",
    "msk = np.random.rand(len(df_impute)) < train_percentage\n",
    "impute_train = df_impute[msk]\n",
    "impute_test  = df_impute[~msk]\n",
    "remove_train = df_remove[msk]\n",
    "remove_test  = df_remove[~msk]\n",
    "\n",
    "X_train_remove = remove_train.drop(\"DX_bl\", axis=1)\n",
    "y_train_remove = remove_train[\"DX_bl\"]\n",
    "X_test_remove  = remove_test.drop(\"DX_bl\", axis=1)\n",
    "y_test_remove  = remove_test[\"DX_bl\"]\n",
    "\n",
    "X_train_impute = impute_train\n",
    "y_train_impute = y_train_remove\n",
    "X_test_impute = impute_test\n",
    "y_test_impute = y_test_remove\n",
    "\n",
    "print(\"For REMOVE:\")\n",
    "print(X_train_remove.shape)\n",
    "print(y_train_remove.shape)\n",
    "print(X_test_remove.shape)\n",
    "print(y_test_remove.shape)\n",
    "\n",
    "print(\"\\nFor IMPUTE:\")\n",
    "print(X_train_impute.shape)\n",
    "print(y_train_impute.shape)\n",
    "print(X_test_impute.shape)\n",
    "print(y_test_impute.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running models on the remove-all-nan dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of principal components that contribute 90% of the variance: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV Log Regression over the rest\n",
    "log_ovr_remove = LogisticRegressionCV(Cs=10, cv = 5, multi_class='ovr')\n",
    "log_ovr_remove.fit(X_train_remove, y_train_remove)\n",
    "\n",
    "# CV Log Regression multinomila\n",
    "log_multi_remove = LogisticRegressionCV(Cs=10, cv = 5, multi_class = 'multinomial')\n",
    "log_multi_remove.fit(X_train_remove, y_train_remove)\n",
    "\n",
    "#Linear discriminant analysis\n",
    "LDA_remove = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "LDA_remove.fit(X_train_remove, y_train_remove)\n",
    "\n",
    "#Quadratic discriminant analysis\n",
    "QDA_remove = discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "QDA_remove.fit(X_train_remove, y_train_remove)\n",
    "\n",
    "# CV k-nearest neighbour\n",
    "knn = KNN()\n",
    "param=np.arange(1,20)\n",
    "param_grid = dict(n_neighbors=param)\n",
    "gs = GridSearchCV(KNN(), param_grid, cv=5, n_jobs=2)\n",
    "gs.fit(X_train_remove, y_train_remove)\n",
    "knn_remove = gs.best_estimator_\n",
    "\n",
    "#CV tree classifier\n",
    "n_estimators =np.arange(1, 20)\n",
    "param_grid = dict(max_depth=n_estimators)\n",
    "gs = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, n_jobs=2)\n",
    "gs.fit(X_train_remove, y_train_remove)\n",
    "tree_remove = gs.best_estimator_\n",
    "\n",
    "#CV Random forest\n",
    "max_features = np.arange(1,len(X_train_remove.columns))              #number of predictors at ech split\n",
    "max_depth = np.arange(1,20)                                   #max depth\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=None)\n",
    "param_grid = dict(max_features=max_features)\n",
    "gs = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
    "gs.fit(X_train_remove, y_train_remove)\n",
    "rf_remove = gs.best_estimator_\n",
    "\n",
    "#Adaboost\n",
    "max_depth = np.arange(1,5)\n",
    "numb_estimators = [10*x for x in range(1,10)]\n",
    "\n",
    "param_grid = {'base_estimator__max_depth':max_depth,\n",
    "              'n_estimators':numb_estimators}\n",
    "DTC = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator = DTC, learning_rate=.05)\n",
    "gs = GridSearchCV(ada, param_grid, cv=5, n_jobs=2)\n",
    "gs.fit(X_train_remove, y_train_remove)\n",
    "ada_remove = gs.best_estimator_\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components = X_train_remove.shape[1])\n",
    "pca.fit(X_train_remove)\n",
    "X_train_pca = pca.transform(X_train_remove)\n",
    "var_ratio = pca.explained_variance_ratio_\n",
    "pca_dict = {}\n",
    "var_sum = 0\n",
    "pca_counter = 0\n",
    "for i in range(len(var_ratio)): \n",
    "    if var_sum < 0.9:\n",
    "        pca_dict[('pc %d'%i)] = X_train_pca[:, i] \n",
    "        var_sum = var_sum + var_ratio[i] \n",
    "        pca_counter = pca_counter + 1\n",
    "dfpca = pd.DataFrame(data = pca_dict)\n",
    "print('The number of principal components that contribute 90% of the variance: {}'.format(pca_counter))\n",
    "\n",
    "X_train_remove_pca = dfpca.values\n",
    "log_ovr_remove_pca = LogisticRegressionCV(Cs=10, cv = 5, multi_class='ovr')\n",
    "log_ovr_remove_pca.fit(X_train_remove_pca, y_train_remove)\n",
    "\n",
    "\n",
    "# SVM\n",
    "# Linear\n",
    "sv_remove_linear = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "sv_remove_linear.fit(X_train_remove, y_train_remove)\n",
    "\n",
    "# Poly\n",
    "sv_remove_poly = SVC(kernel='poly', degree=2, decision_function_shape='ovr')\n",
    "sv_remove_poly.fit(X_train_remove, y_train_remove)\n",
    "\n",
    "# RBF\n",
    "sv_remove_rbf = SVC(kernel='rbf', decision_function_shape='ovr')\n",
    "sv_remove_rbf.fit(X_train_remove, y_train_remove)\n",
    "\n",
    "# Sigmoid\n",
    "sv_remove_sig = SVC(kernel='sigmoid', decision_function_shape='ovr')\n",
    "sv_remove_sig.fit(X_train_remove, y_train_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For models running on remove-all-nan dataset:\n",
      "=============================================\n",
      "logistic OVR train accurcy is 0.636\n",
      "logistic OVR test accurcy is 0.607\n",
      "\n",
      "\n",
      "logistic Multi train accurcy is 0.636\n",
      "logistic Multi test accurcy is 0.632\n",
      "\n",
      "\n",
      "LDA train accurcy is 0.612\n",
      "LDA test accurcy is 0.607\n",
      "\n",
      "\n",
      "QDA train accurcy is 0.531\n",
      "QDA test accurcy is 0.448\n",
      "\n",
      "\n",
      "KNN train accurcy is 0.621\n",
      "KNN test accurcy is 0.483\n",
      "\n",
      "\n",
      "tree train accurcy is 0.643\n",
      "tree test accurcy is 0.627\n",
      "\n",
      "\n",
      "Random forest train accurcy is 0.997\n",
      "Random forest test accurcy is 0.572\n",
      "\n",
      "\n",
      "AdaBoost train accurcy is 0.667\n",
      "AdaBoost test accurcy is 0.662\n",
      "\n",
      "\n",
      "Linear SVM train accurcy is 0.665\n",
      "Linear SVM test accurcy is 0.647\n",
      "\n",
      "\n",
      "Polynomial SVM (Degree = 2) train accurcy is 0.675\n",
      "Polynomial SVM (Degree = 2) test accurcy is 0.627\n",
      "\n",
      "\n",
      "RBF SVM train accurcy is 0.777\n",
      "RBF SVM test accurcy is 0.527\n",
      "\n",
      "\n",
      "Sigmoid SVM train accurcy is 0.259\n",
      "Sigmoid SVM test accurcy is 0.179\n",
      "\n",
      "\n",
      "PCA (3) train accurcy is 0.517\n",
      "PCA (3) test accurcy is 0.433\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_remove = [log_ovr_remove, log_multi_remove, LDA_remove, QDA_remove, knn_remove,\n",
    "                 tree_remove, rf_remove, ada_remove, sv_remove_linear, sv_remove_poly, sv_remove_rbf, \n",
    "                 sv_remove_sig, log_ovr_remove_pca]\n",
    "models_name = ['logistic OVR', 'logistic Multi', 'LDA', 'QDA', 'KNN', 'tree', 'Random forest', 'AdaBoost',\n",
    "               'Linear SVM', 'Polynomial SVM (Degree = 2)', 'RBF SVM', 'Sigmoid SVM', 'PCA (3)']\n",
    "\n",
    "test_score_remove =[]\n",
    "zipped = zip(models_remove, models_name)\n",
    "print(\"For models running on remove-all-nan dataset:\")\n",
    "print(\"=============================================\")\n",
    "for i,r in zipped:\n",
    "    if r != 'PCA (3)':\n",
    "        print(r+' train accurcy is %0.3f' % (i.score (X_train_remove,y_train_remove)))\n",
    "        print(r+' test accurcy is %0.3f' % (i.score (X_test_remove,y_test_remove)))\n",
    "        print(\"\\n\")\n",
    "        test_score_remove.append(i.score (X_test_remove,y_test_remove))\n",
    "    else:\n",
    "        X_test_pca = pca.transform(X_test_remove)\n",
    "        X_test_remove_pca = X_test_pca[:, 0:pca_counter]\n",
    "        print(r+' train accurcy is %0.3f' % (i.score (X_train_remove_pca,y_train_remove)))\n",
    "        print(r+' test accurcy is %0.3f' % (i.score (X_test_remove_pca,y_test_remove)))\n",
    "        print(\"\\n\")\n",
    "        #test_score_remove.append(i.score (X_train_remove_pca,y_test_remove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running models on the imputed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV Log Regression over the rest\n",
    "log_ovr_impute = LogisticRegressionCV(Cs=10, cv = 5, multi_class='ovr')\n",
    "log_ovr_impute.fit(X_train_impute, y_train_impute)\n",
    "\n",
    "# CV Log Regression multinomila\n",
    "log_multi_impute = LogisticRegressionCV(Cs=10, cv = 5, multi_class = 'multinomial')\n",
    "log_multi_impute.fit(X_train_impute, y_train_impute)\n",
    "\n",
    "#Linear discriminant analysis\n",
    "LDA_impute = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "LDA_impute.fit(X_train_impute, y_train_impute)\n",
    "\n",
    "#Quadratic discriminant analysis\n",
    "QDA_impute = discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "QDA_impute.fit(X_train_impute, y_train_impute)\n",
    "\n",
    "# CV k-nearest neighbour\n",
    "knn = KNN()\n",
    "param=np.arange(1,20)\n",
    "param_grid = dict(n_neighbors=param)\n",
    "gs = GridSearchCV(KNN(), param_grid, cv=5, n_jobs=2)\n",
    "gs.fit(X_train_impute, y_train_impute)\n",
    "knn_impute = gs.best_estimator_\n",
    "\n",
    "#CV tree classifier\n",
    "n_estimators =np.arange(1, 20)\n",
    "param_grid = dict(max_depth=n_estimators)\n",
    "gs = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, n_jobs=2)\n",
    "gs.fit(X_train_impute, y_train_impute)\n",
    "tree_impute = gs.best_estimator_\n",
    "\n",
    "#CV Random forest\n",
    "max_features = np.arange(1,len(X_train_impute.columns))              #number of predictors at ech split\n",
    "max_depth = np.arange(1,20)                                   #max depth\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=None)\n",
    "param_grid = dict(max_features=max_features)\n",
    "gs = GridSearchCV(rf, param_grid, cv=5, n_jobs=2)\n",
    "gs.fit(X_train_impute, y_train_impute)\n",
    "rf_impute = gs.best_estimator_\n",
    "\n",
    "#Adaboost\n",
    "max_depth = np.arange(1,5)\n",
    "numb_estimators = [10*x for x in range(1,10)]\n",
    "\n",
    "param_grid = {'base_estimator__max_depth':max_depth,\n",
    "              'n_estimators':numb_estimators}\n",
    "DTC = DecisionTreeClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator = DTC, learning_rate=.05)\n",
    "gs = GridSearchCV(ada, param_grid, cv=5, n_jobs=2)\n",
    "gs.fit(X_train_impute, y_train_impute)\n",
    "ada_impute = gs.best_estimator_\n",
    "\n",
    "print('SVM')\n",
    "# SVM\n",
    "# Linear\n",
    "sv_impute_linear = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "sv_impute_linear.fit(X_train_impute, y_train_impute)\n",
    "'''\n",
    "# Poly\n",
    "sv_impute_poly = SVC(kernel='poly', degree=2, decision_function_shape='ovr')\n",
    "sv_impute_poly.fit(X_train_impute, y_train_impute)\n",
    "'''\n",
    "# RBF\n",
    "sv_impute_rbf = SVC(kernel='rbf', decision_function_shape='ovr')\n",
    "sv_impute_rbf.fit(X_train_impute, y_train_impute)\n",
    "\n",
    "# Sigmoid\n",
    "sv_impute_sig = SVC(kernel='sigmoid', decision_function_shape='ovr')\n",
    "sv_impute_sig.fit(X_train_impute, y_train_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For models running on imputed dataset:\n",
      "=============================================\n",
      "logistic OVR train accurcy is 0.425\n",
      "logistic OVR test accurcy is 0.358\n",
      "\n",
      "\n",
      "logistic Multi train accurcy is 0.395\n",
      "logistic Multi test accurcy is 0.313\n",
      "\n",
      "\n",
      "LDA train accurcy is 0.721\n",
      "LDA test accurcy is 0.602\n",
      "\n",
      "\n",
      "QDA train accurcy is 1.000\n",
      "QDA test accurcy is 0.985\n",
      "\n",
      "\n",
      "KNN train accurcy is 0.388\n",
      "KNN test accurcy is 0.279\n",
      "\n",
      "\n",
      "tree train accurcy is 1.000\n",
      "tree test accurcy is 1.000\n",
      "\n",
      "\n",
      "Random forest train accurcy is 1.000\n",
      "Random forest test accurcy is 1.000\n",
      "\n",
      "\n",
      "AdaBoost train accurcy is 1.000\n",
      "AdaBoost test accurcy is 1.000\n",
      "\n",
      "\n",
      "Linear SVM train accurcy is 0.412\n",
      "Linear SVM test accurcy is 0.308\n",
      "\n",
      "\n",
      "RBF SVM train accurcy is 1.000\n",
      "RBF SVM test accurcy is 0.179\n",
      "\n",
      "\n",
      "Sigmoid SVM train accurcy is 0.259\n",
      "Sigmoid SVM test accurcy is 0.179\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_impute = [log_ovr_impute, log_multi_impute, LDA_impute, QDA_impute, knn_impute,\\\n",
    "          tree_impute, rf_impute, ada_impute, sv_impute_linear, sv_impute_rbf, sv_impute_sig]\n",
    "models_name = ['logistic OVR', 'logistic Multi', 'LDA', 'QDA', 'KNN', 'tree', 'Random forest', 'AdaBoost',\n",
    "               'Linear SVM', 'RBF SVM', 'Sigmoid SVM']\n",
    "\n",
    "test_score_impute =[]\n",
    "zipped = zip(models_impute, models_name)\n",
    "print(\"For models running on imputed dataset:\")\n",
    "print(\"=============================================\")\n",
    "for i,r in zipped:\n",
    "    print(r+' train accurcy is %0.3f' % (i.score (X_train_impute,y_train_impute)))\n",
    "    print(r+' test accurcy is %0.3f' % (i.score (X_test_impute,y_test_impute)))\n",
    "    print(\"\\n\")\n",
    "    test_score_impute.append(i.score (X_test_impute,y_test_impute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove-All-NaN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
